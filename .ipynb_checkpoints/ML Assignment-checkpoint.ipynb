{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a8c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diabetes Analysis & Prediction\n",
    "# ML ASSIGNMENT\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# for preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "\n",
    "# classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3873a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f650574",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2397ddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cc5dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness']\n",
    "num_cols = ['Insulin',  'BMI', 'DiabetesPedigreeFunction', 'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74250a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f694f177",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2009c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c4baf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e90db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa35873",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af6603",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"shape before removing duplicates: {df.shape}\")\n",
    "df.drop_duplicates(inplace = True)\n",
    "print(f\"shape after removing duplicates: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fdd2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Outcome'].value_counts().plot(kind = 'bar', color=['red', 'blue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492f9828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_palette(\"pastel\")\n",
    "plt.figure(figsize=(20,10))\n",
    "for i, col in enumerate(num_cols):\n",
    "    plt.subplot(2,3, i+1)\n",
    "    sns.boxplot(data = df, x = 'Outcome', y = col, palette = 'Pastel1' )\n",
    "    sns.swarmplot(data = df, x = 'Outcome', y = col, palette = 'Set1')\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.title(f\"{col}\", fontsize = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f9aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(600,300))\n",
    "for i, col in enumerate(cat_cols):\n",
    "    plt.subplot(2,4, i+1)\n",
    "    sns.countplot(data = df, x = col, palette = 'Set1')\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.title(f\"{col}\", fontsize = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af181d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(600,300))\n",
    "for i, col in enumerate(cat_cols):\n",
    "    plt.subplot(2,4, i+1)\n",
    "    sns.countplot(data = df, x = col, hue = 'Outcome', palette = 'Set1')\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.title(f\"{col}\", fontsize = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a142c00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100,50))\n",
    "for i, col in enumerate(cat_cols):\n",
    "    plt.subplot(4,2, i+1)\n",
    "    sns.swarmplot(data = df, x = col, y = 'Age', hue = 'Outcome', palette = 'Set1')\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.title(f\"{col}\", fontsize = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffaca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[['Insulin',  'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']],hue = 'Outcome',palette = 'Set1', diag_kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877807da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,12))\n",
    "sns.heatmap(df.corr(), annot = True, fmt = '.2f', cmap = 'viridis', cbar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9e2c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['Outcome'].sort_values(ascending = False)[1:].plot(kind = 'bar', lw = .4, color = 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11c0092",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90813855",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Outcome', axis = 1)\n",
    "y = df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461bd975",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8861b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize only numerical columns\n",
    "scaler = StandardScaler()\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399f60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = ['LogisticRegression','KNeighborsClassifier','SVC','DecisionTreeClassifier','RandomForestClassifier','GradientBoostingClassifier','AdaBoostClassifier','XGBClassifier']\n",
    "value = [LogisticRegression(random_state=9), KNeighborsClassifier(), SVC(), DecisionTreeClassifier(), RandomForestClassifier(), GradientBoostingClassifier()]\n",
    "models = dict(zip(key,value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9088c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=KFold(5, shuffle=True, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2b893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_check(X, y, classifiers, cv):\n",
    "    \n",
    "    ''' A function for testing multiple classifiers and return several metrics. '''\n",
    "    \n",
    "    model_table = pd.DataFrame()\n",
    "\n",
    "    row_index = 0\n",
    "    for cls in classifiers:\n",
    "\n",
    "        MLA_name = cls.__class__.__name__\n",
    "        model_table.loc[row_index, 'Model Name'] = MLA_name\n",
    "        \n",
    "        cv_results = cross_validate(\n",
    "            cls,\n",
    "            X,\n",
    "            y,\n",
    "            cv=cv,\n",
    "            scoring=('accuracy','f1','roc_auc'),\n",
    "            return_train_score=True,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        model_table.loc[row_index, 'Train Roc/AUC Mean'] = cv_results['train_roc_auc'].mean()\n",
    "        model_table.loc[row_index, 'Test Roc/AUC Mean'] = cv_results['test_roc_auc'].mean()\n",
    "        model_table.loc[row_index, 'Test Roc/AUC Std'] = cv_results['test_roc_auc'].std()\n",
    "        model_table.loc[row_index, 'Train Accuracy Mean'] = cv_results['train_accuracy'].mean()\n",
    "        model_table.loc[row_index, 'Test Accuracy Mean'] = cv_results['test_accuracy'].mean()\n",
    "        model_table.loc[row_index, 'Test Acc Std'] = cv_results['test_accuracy'].std()\n",
    "        model_table.loc[row_index, 'Train F1 Mean'] = cv_results['train_f1'].mean()\n",
    "        model_table.loc[row_index, 'Test F1 Mean'] = cv_results['test_f1'].mean()\n",
    "        model_table.loc[row_index, 'Test F1 Std'] = cv_results['test_f1'].std()\n",
    "        model_table.loc[row_index, 'Time'] = cv_results['fit_time'].mean()\n",
    "\n",
    "        row_index += 1        \n",
    "\n",
    "    model_table.sort_values(by=['Test F1 Mean'],\n",
    "                            ascending=False,\n",
    "                            inplace=True)\n",
    "\n",
    "    return model_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71075673",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_models = model_check(X_train, y_train, models.values(), cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a839b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58eebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_imp(classifiers, X, y, bins):\n",
    "    \n",
    "    ''' A function for displaying feature importances'''\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for ax, classifier in zip(axes, classifiers):\n",
    "\n",
    "        try:\n",
    "            classifier.fit(X, y)\n",
    "            feature_imp = pd.DataFrame(sorted(\n",
    "                zip(classifier.feature_importances_, X.columns)),\n",
    "                                       columns=['Value', 'Feature'])\n",
    "\n",
    "            sns.barplot(x=\"Value\",\n",
    "                        y=\"Feature\",\n",
    "                        data=feature_imp.sort_values(by=\"Value\",\n",
    "                                                     ascending=False),\n",
    "                        ax=ax,\n",
    "                        palette='plasma')\n",
    "            plt.title('Features')\n",
    "            plt.tight_layout()\n",
    "            ax.set(title=f'{classifier.__class__.__name__} Feature Impotances')\n",
    "            ax.xaxis.set_major_locator(MaxNLocator(nbins=bins))\n",
    "        except:\n",
    "            continue\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2eacb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_imp([RandomForestClassifier(), DecisionTreeClassifier()], X_train, y_train, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c98cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_models.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacd6a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,5))\n",
    "sns.barplot(data=raw_models, x = 'Train Accuracy Mean', y = 'Model Name', palette = 'Set1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba2a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,5))\n",
    "sns.barplot(data=raw_models, x = 'Test Accuracy Mean', y = 'Model Name', palette = 'Set1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eed989",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_models.set_index('Model Name', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ce0c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18,8))\n",
    "raw_models[['Train Accuracy Mean','Test Accuracy Mean' ]].plot(kind = 'barh', colormap = cm.get_cmap('Spectral'), legend = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc952e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report,accuracy_score\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print(f'Accuracy score: {round(accuracy_score(y_test, pred) * 100, 2)} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1046bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train score - \" + str(lr.score(X_train, y_train)))\n",
    "print(\"test score - \" + str(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c86aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_lg = confusion_matrix(y_test,pred)\n",
    "sns.set(font_scale=1.4) # for label size\n",
    "sns.heatmap(cm_lg, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e37b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
